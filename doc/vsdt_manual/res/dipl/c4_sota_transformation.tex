\chapter{Model Transformation Tools}
\label{chapter:transformation}

% in diesem kapitel...
In this chapter we will have a look on existing tools providing the kind of model transformation needed for the mapping from BPMN to BPEL and JIAC. As we will see there are a number of frameworks for model transformation based on the Eclipse Modeling Framework (EMF). We will introduce these frameworks briefly. Then we will have a closer look at the tool used for the mappings in this diploma thesis.



\section{Eclipse Generative Modeling Tools}

% GMT
In the Eclipse Generative Modeling Tools Project (GMT) \cite{GMT} there are a number of sub-projects about Model Driven Engineering and model-to-model and model-to-code transformation. Note that there are other transformation frameworks for other meta models than EMF, but since EMF is very well integrated in Eclipse and most of the workflow models used in this thesis are designed in EMF we will concentrate on this framework.

ATL \cite{JK06a} is a  model transformation system developed as part of the ATLAS Model Management Architecture. It is well integrated into the Eclipse platform, providing its own editor, compiler, debugger and virtual machine. In ATL a transformation can be defined by a set of textual rules.

There are some other transformation frameworks, such as MTF\footnote{\url{http://www.alphaworks.ibm.com/tech/mtf}} and Tefkat\footnote{\url{http://tefkat.sourceforge.net/}} similar to ATL. They all work on EMF and use textual rules for defining the mapping from the source model to the target model.

However, the examples given in the transformation systems' documentations are limited to straight-forward transformations, like from \emph{Classes} to \emph{Tables}, from \emph{Students} to \emph{Persons} or from \emph{arabic} to \emph{roman} numbers. It is not clear in how far these transformation systems are suited for the transformation of workflow models.

% open Architecture Ware
Another promising approach is that of Open Architecture Ware (oAW), another subproject of the GMT project. Similar to the above, rules can be defined in its own textual syntax, but it can also integrate rules from other transformation systems and operate on different metametamodells. It can be used for validation, endogenous and exogenous model transformations and code generation, including the generation of a full-featured source code editor for a given BNF.



\section{The Tiger EMF Transformation Project}
\label{sec:emt}

% introduction
The \emph{Tiger EMF Transformation Project} \cite{EMT}, also referred to as EMT, is a model transformation framework for EMF models developed by the TFS Group at TU Berlin. Similar to the \emph{Attributed Graph Grammar System} (AGG) \cite{AGG} the transformation is defined by \emph{graph transformation rules}.

% endogen vs. exogen
The main purpose of EMT is to provide a framework for defining endogenous rules, e.g. for the refactoring of models of only one language, which is intended to be used for complex modeling operations and model refactorings and optimization, as can be seen in \cite{emt_paper}. However, in its latest version EMT is also suited for exogenous transformations, i.e. model-to-model transformations.

% editor, noch etwas buggy
In contrast to many other model transformation tools EMT comes with a visual editor as shown in figure \ref{fig:emt_gui}. Using this editor facilitates the creation of rules greatly. The editor has recently been implemented in the course of a diploma thesis \cite{emt_thesis} at the TFS Group.

\begin{figure}[htp]
	\centering
	\includegraphics[width=.7\textwidth]{figures/screens/emt_gui.png}
	\caption[EMT Visual Rule Editor]{The EMT Visual Rule Editor showing a rule of a transformation model for mapping activity diagrams to petri nets}
	\label{fig:emt_gui}
\end{figure}

The following sections will introduce you to the most important concepts of the EMT transformation framework.


\subsection{Transformation Rules}

% lhs und rhs
The transformation rules consist of a left hand and a right hand rule side (referred to as LHS and RHS) which are both models of some language. The LHS serves as a pattern that has to be found in the source graph to be transformed. Elements of the LHS can be mapped to elements of the RHS of the same type. Those elements then can be modified by the rule. Elements of the LHS which do not have a mapping to the RHS are deleted and vice versa elements in the RHS that are not mapped to by the LHS are created in the course of the rule's execution.

% variables, nacs
Besides these most basic concepts the rules can have negative application conditions (NACs) and variables. Variables are needed to refer attributes of elements from the LHS in the RHS and to define attribute conditions in the LHS. NACs are patterns that \emph{must not} apply for the rule to be executed. Similar to the RHS, elements of a NAC can be identified with elements of the LHS. If the pattern given in the LHS is found but also the pattern of one of the NACs is found with the mapped elements being the same as in the LHS then the rule may not be applied.

% execution order, layers
The rules are executed in random order by default. To assure that a rule is not executed before another rule has been applied as often as possible the rules can be subdivided into layers. The rules of each layer will be executed as long as possible before changing to the next layer.


\subsection{Backtracking and Queries}

The pattern matching needed for the application of the rules is done by a backtracking algorithm. Each symbol in the rule's LHS is represented by a \verb|Variable|\footnote{not to be confused with the ``variables'' for attribute values} which can hold a number of \verb|Queries|. There are different kinds of queries for different constraints that have to be checked: The most important are \verb|Source|- and \verb|TargetQueries|, which represent references among elements of a rule side. Further there are \verb|InjectivityQueries|, which check if two variables are (not) instantiated with the same object, \verb|TypeQueries| and \verb|VariableQueries|.

In the backtracking algorithm the first variable is instantiated with a possible value from its domain, the set of instances of the given type contained in the source model. Next the remaining variables' domains are reduced by evaluating the last variables queries. Only those instances are retained that are not in conflict with any of the queries. If there are possible instances left for the next variable the process is continued until each variable is instantiated and the rule can be applied. Otherwise the previous variable is instantiated with the next value. If no match is found the rule can not be applied.


\subsection{AGG and EMT}

% agg mehr features, agg propriet√§r, emt emf basiert
Basically EMT is providing the same functionality as AGG. Still AGG is providing some additional features for the analysis and evaluation of rules. Rules of a transformation can be tested with critical pair analysis and executed step by step. But while AGG is using a proprietary format for \emph{type graphs} (metamodels) and \emph{graphs} (instances of type graphs, models), EMT is based on the popular EMF framework, making it more usable in practice. 

% containment
However, using the EMT framework also brings some restrictions. In an EMT model each element has to be contained in a container, so it is transitively contained in the root element which again is contained in some resource. Having some element in this containment structure referencing another element which is not in a container, and thus not in a resource, the model can not be made persistent anymore. Thus EMT can handle only a subset of the rules possible with AGG.


\subsection{Interpretation and Compilation of Rules}

Once the rules have been created in the visual editor they can be either interpreted by the AGG engine or compiled to executable Java code that can be used with no requirements other than EMF.

% interpretation
For the interpretation the EMT rule model is first exported to the AGG metamodel in a straightforward way. The resulting model then can be transformed using AGG and imported back to EMF. This has the advantage that the advanced features of AGG can be used for the evaluation of the rules. Still this approach is not suited very well for practical use.

% compilation
The rule model can be used for compiling the rules, too, i.e. generating rule classes. This is done using Java Emitter Templates (JET), the generator used by EMF \cite{EMF}. The compiler creates a pair of \verb|Rule| and \verb|Wrapper| classes for each rule as well as a \verb|Transformation| class providing access to the rules. The wrapper class is providing the information needed for the pattern matching (the LHS and NAC) while the rule class is needed for execution of the rule (the RHS) as well as for undo and redo. Additionally a set of helper classes is generated. These classes are needed e.g. for the matchfinding. They are the same for each set of rules, but generating them together with the rules has the advantage of making the generated classes independent of the EMT plugin.

% use of reflective api
Both the interpreter and the compiler make use of the EMF metamodel and the reflective API. The transformation model to be interpreted and compiled is a EMF model itself and the code generation is only possible by using reflective methods.
\\
\\

We decided to use the EMT framework for the model transformations to be implemented in this thesis. While being very powerful the framework consists of only about a dozen of classes and has no more plugin dependencies than EMF.

Since the rules are compiled to Java classes they can be modified and extended afterwards. Thus there are no syntactical restrictions to the right rule sides, which can consist of conditions, loops and arbitrary method calls. This is especially important due to the many subtypes of the BPMN elements.

The graph transformation based approach has a clear formal background. With the concept of LHS, NACs and conditions and using EMF's reflective API even very complex rules involving several interconnected elements can be realized.

In the next chapter the mappings from BPMN to BPEL and JIAC will be introduced. We will explain how the elements of BPMN are mapped to JADL elements and how agent concepts could be modeled using BPMN.